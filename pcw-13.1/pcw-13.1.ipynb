{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = glob('language-test/*')\n",
    "language_A = glob('language-A/*')\n",
    "language_B = glob('language-B/*')\n",
    "language_C = glob('language-C/*')\n",
    "\n",
    "language_A_texts = []\n",
    "language_B_texts = []\n",
    "language_C_texts = []\n",
    "language_test = []\n",
    "\n",
    "cMap = {\n",
    "    \"A\": 0,\n",
    "    \"e\": 1,\n",
    "    \"g\": 2,\n",
    "    \"k\": 3,\n",
    "    \"o\": 4,\n",
    "    \"p\": 5,\n",
    "    \"t\": 6\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in language_A:\n",
    "    # open it as a read file in binary mode\n",
    "    with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "        language_A_texts.append(text)\n",
    "        \n",
    "for path in language_B:\n",
    "    # open it as a read file in binary mode\n",
    "    with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "        language_B_texts.append(text)\n",
    "        \n",
    "for path in language_C:\n",
    "    # open it as a read file in binary mode\n",
    "    with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "        language_C_texts.append(text)\n",
    "        \n",
    "for path in test:\n",
    "    # open it as a read file in binary mode\n",
    "    with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "        language_test.append((text, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findInitialDistribution(textSet):\n",
    "    distributionMap = {}\n",
    "    for text in textSet:\n",
    "        distributionMap[text[0]] = distributionMap.get(text[0],0) + 1\n",
    "    \n",
    "    od = collections.OrderedDict(sorted(distributionMap.items()))\n",
    "    return np.array(list(od.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(transitions, cMap):\n",
    "    n = 7\n",
    "    \n",
    "    M = np.zeros((n,n))\n",
    "    \n",
    "    for t in transitions:\n",
    "        t = list(t)\n",
    "        for (i,j) in zip(t,t[1:]):\n",
    "            M[cMap[j],cMap[i]] += 1\n",
    "\n",
    "    #now convert to probabilities:\n",
    "    M_prob = M / M.sum(axis=0)\n",
    "    \n",
    "    return M_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_probability(text, transition_matrix, initial_distribution, cMap):\n",
    "    initial = initial_distribution[cMap[text[0]]]\n",
    "    probability = initial\n",
    "    prev = cMap[text[0]]\n",
    "    for c in text[1:]:\n",
    "        new_prob = transition_matrix[cMap[c],prev]\n",
    "        prev = cMap[c]\n",
    "        probability *= new_prob\n",
    "    \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "initDistA = findInitialDistribution(language_A_texts)\n",
    "initDistB = findInitialDistribution(language_B_texts)\n",
    "initDistC = findInitialDistribution(language_C_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  [0.07 0.03 0.17 0.2  0.17 0.13 0.23]\n",
      "B:  [0.17 0.13 0.2  0.1  0.2  0.1  0.1 ]\n",
      "C:  [0.23 0.1  0.17 0.07 0.17 0.1  0.17]\n"
     ]
    }
   ],
   "source": [
    "initDistA_norm = initDistA/sum(initDistA)\n",
    "initDistB_norm = initDistB/sum(initDistB)\n",
    "initDistC_norm = initDistC/sum(initDistC)\n",
    "print(\"A: \",np.around(initDistA_norm,2))\n",
    "print(\"B: \",np.around(initDistB_norm,2))\n",
    "print(\"C: \",np.around(initDistC_norm,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transA = transition_matrix(language_A_texts, cMap)\n",
    "transB = transition_matrix(language_B_texts, cMap)\n",
    "transC = transition_matrix(language_C_texts, cMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: \n",
      "[[0.018 0.027 0.264 0.319 0.017 0.272 0.02 ]\n",
      " [0.03  0.017 0.278 0.285 0.026 0.306 0.029]\n",
      " [0.232 0.242 0.029 0.037 0.243 0.036 0.227]\n",
      " [0.212 0.208 0.025 0.042 0.216 0.018 0.236]\n",
      " [0.02  0.029 0.33  0.246 0.017 0.295 0.024]\n",
      " [0.222 0.258 0.05  0.029 0.233 0.027 0.23 ]\n",
      " [0.265 0.22  0.025 0.042 0.248 0.045 0.234]]\n",
      "B: \n",
      "[[0.024 0.02  0.453 0.023 0.416 0.038 0.402]\n",
      " [0.041 0.03  0.408 0.023 0.433 0.058 0.472]\n",
      " [0.283 0.253 0.038 0.279 0.042 0.308 0.033]\n",
      " [0.035 0.023 0.    0.023 0.    0.019 0.   ]\n",
      " [0.289 0.314 0.051 0.256 0.057 0.308 0.057]\n",
      " [0.029 0.037 0.    0.093 0.    0.019 0.   ]\n",
      " [0.301 0.325 0.051 0.302 0.051 0.25  0.036]]\n",
      "C: \n",
      "[[0.621 0.058 0.081 0.052 0.067 0.042 0.068]\n",
      " [0.054 0.607 0.07  0.057 0.053 0.089 0.071]\n",
      " [0.071 0.058 0.601 0.062 0.051 0.087 0.08 ]\n",
      " [0.054 0.072 0.065 0.59  0.06  0.04  0.059]\n",
      " [0.068 0.056 0.058 0.079 0.616 0.071 0.059]\n",
      " [0.085 0.075 0.051 0.076 0.083 0.598 0.064]\n",
      " [0.047 0.072 0.074 0.084 0.069 0.071 0.598]]\n"
     ]
    }
   ],
   "source": [
    "print(\"A: \")\n",
    "print(np.around(transA,3))\n",
    "print(\"B: \")\n",
    "print(np.around(transB,3))\n",
    "print(\"C: \")\n",
    "print(np.around(transC,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language-test-3: B | [1.34443778e-46 1.00000000e+00 8.64666350e-59]\n",
      "language-test-4: A | [1.00000000e+00 0.00000000e+00 9.91152197e-47]\n",
      "language-test-5: A | [1.0000000e+00 0.0000000e+00 1.1527412e-39]\n",
      "language-test-2: A | [1.00000000e+00 0.00000000e+00 3.03765345e-34]\n",
      "language-test-7: A | [1.00000000e+00 0.00000000e+00 5.34293923e-42]\n",
      "language-test-0: C | [7.0087509e-61 0.0000000e+00 1.0000000e+00]\n",
      "language-test-9: A | [1.00000000e+00 0.00000000e+00 3.58533799e-46]\n",
      "language-test-8: C | [2.21983772e-81 0.00000000e+00 1.00000000e+00]\n",
      "language-test-1: C | [4.62774258e-68 0.00000000e+00 1.00000000e+00]\n",
      "language-test-6: B | [5.29263175e-63 1.00000000e+00 2.69984205e-62]\n"
     ]
    }
   ],
   "source": [
    "for c, test in enumerate(language_test):\n",
    "    returnMap = {\n",
    "        0: \"A\",\n",
    "        1: \"B\",\n",
    "        2: \"C\"\n",
    "    }\n",
    "    # probA = P(language|String)\n",
    "    # find_probability(test, transA, initDistA_norm, cMap) = P(String|Language)\n",
    "    # 1/3  = P(String) (uniform prior)\n",
    "    probA = find_probability(test[0], transA, initDistA_norm, cMap) * 1/3\n",
    "    probB = find_probability(test[0], transB, initDistB_norm, cMap) * 1/3\n",
    "    probC = find_probability(test[0], transC, initDistC_norm, cMap) * 1/3\n",
    "    res = np.array([probA/(probA+probB+probC), probB/(probA+probB+probC), probC/(probA+probB+probC)])\n",
    "    testName = test[1].split(\"/\")[1]\n",
    "    print(f\"{testName}:\", returnMap[np.argmax(res)], \"|\" , res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
